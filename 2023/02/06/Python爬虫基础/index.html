<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Python爬虫基础 | bkysの客栈</title><meta name="author" content="bkys"><meta name="copyright" content="bkys"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="爬虫是什么 爬虫的本质：模拟浏览器打开网页，捕获网页中我们想要的那部分数据。 入门：爬虫是一种自动抓取互联网信息的程序或脚本。主要用于搜索引擎，对一些网站的数据进行大量解析和收集。简单的爬虫程序通过request模块几行就可以对收据进行批量收集，， 进阶学习：想要学习好并没有那么简单。它关系到了计算机网络，前端开发，后端编程。对于爬取到的数据进行存储还需要学习数据库，对于有反爬措施的网站还需要进行">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫基础">
<meta property="og:url" content="http://bkystop.github.io/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="bkysの客栈">
<meta property="og:description" content="爬虫是什么 爬虫的本质：模拟浏览器打开网页，捕获网页中我们想要的那部分数据。 入门：爬虫是一种自动抓取互联网信息的程序或脚本。主要用于搜索引擎，对一些网站的数据进行大量解析和收集。简单的爬虫程序通过request模块几行就可以对收据进行批量收集，， 进阶学习：想要学习好并没有那么简单。它关系到了计算机网络，前端开发，后端编程。对于爬取到的数据进行存储还需要学习数据库，对于有反爬措施的网站还需要进行">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://th.bing.com/th/id/OIP.zyNsZRAsDyvjlDQ4-I9tPQHaDt?w=311&h=175&c=7&r=0&o=5&dpr=1.3&pid=1.7">
<meta property="article:published_time" content="2023-02-06T06:23:42.000Z">
<meta property="article:modified_time" content="2023-04-09T09:10:25.981Z">
<meta property="article:author" content="bkys">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Python爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://th.bing.com/th/id/OIP.zyNsZRAsDyvjlDQ4-I9tPQHaDt?w=311&h=175&c=7&r=0&o=5&dpr=1.3&pid=1.7"><link rel="shortcut icon" href="https://th.bing.com/th/id/OIP.GKw_Efoi-Jsf_OzGf3BSDwHaEd?w=269&h=180&c=7&r=0&o=5&dpr=1.3&pid=1.7"><link rel="canonical" href="http://bkystop.github.io/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Python爬虫基础',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-09 17:10:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="bkysの客栈" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://th.bing.com/th/id/OIP.GKw_Efoi-Jsf_OzGf3BSDwHaEd?w=269&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光机</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://th.bing.com/th/id/OIP.zyNsZRAsDyvjlDQ4-I9tPQHaDt?w=311&amp;h=175&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7')"><nav id="nav"><span id="blog-info"><a href="/" title="bkysの客栈"><span class="site-name">bkysの客栈</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时光机</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python爬虫基础</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-02-06T06:23:42.000Z" title="Created 2023-02-06 14:23:42">2023-02-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-04-09T09:10:25.981Z" title="Updated 2023-04-09 17:10:25">2023-04-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Python%E7%AF%87/">Python篇</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Python爬虫基础"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="爬虫是什么"><a href="#爬虫是什么" class="headerlink" title="爬虫是什么"></a>爬虫是什么</h2><ul>
<li>爬虫的本质：模拟浏览器打开网页，捕获网页中我们想要的那部分数据。</li>
<li>入门：爬虫是一种自动抓取互联网信息的程序或脚本。主要用于搜索引擎，对一些网站的数据进行大量解析和收集。简单的爬虫程序通过request模块几行就可以对收据进行批量收集，，</li>
<li>进阶学习：想要学习好并没有那么简单。它关系到了计算机网络，前端开发，后端编程。对于爬取到的数据进行存储还需要学习数据库，对于有反爬措施的网站还需要进行反反爬，逆向等。为了能快速准确的采集到我们需要的数据，爬虫的核心在于并发和逆向，这将大大提高我们的效率。在人工智能时代，模型的训练是需要大量数据的，爬虫与机器学习，数据分析更是有密不可分的关系。</li>
</ul>
<h2 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h2><h3 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h3><ol>
<li>简介</li>
</ol>
<p> HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于万维网（WWW:World Wide Web ）服务器与本地浏览器之间传输超文本的传送协议。HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息。</p>
<ol start="2">
<li>http协议的特性</li>
</ol>
<blockquote>
<ol>
<li>基于TCP/IP协议</li>
</ol>
<p>http协议是基于TCP/IP协议之上的应用层协议。</p>
<ol start="2">
<li> 基于请求－响应模式</li>
</ol>
<p>HTTP协议规定,请求从客户端发出,最后服务器端响应该请求并返回。换句话说,肯定是先从客户端开始建立通信的,服务器端在没有接收到请求之前不会发送响应</p>
<ol start="3">
<li>无状态保存</li>
</ol>
<p>HTTP是一种不保存状态,即无状态(stateless)协议。HTTP协议自身不对请求和响应之间的通信状态进行保存。也就是说在HTTP这个级别,协议对于发送过的请求或响应都不做持久化处理。</p>
<p>使用HTTP协议,每当有新的请求发送时,就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。这是为了更快地处理大量事务,确保协议的可伸缩性,而特意把HTTP协议设计成如此简单的。</p>
<ol start="4">
<li> 短连接和长连接</li>
</ol>
<p>HTTP1.0默认使用的是短连接。浏览器和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。<br>HTTP/1.1起，默认使用长连接。要使用长连接，客户端和服务器的HTTP首部的Connection都要设置为keep-alive，才能支持长连接。<br>HTTP长连接，指的是复用TCP连接。多个HTTP请求可以复用同一个TCP连接，这就节省了TCP连接建立和断开的消耗。</p>
</blockquote>
<ol start="3">
<li>http请求协议与响应协议</li>
</ol>
<img src="/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/image-20230406143839579.png" class>

<blockquote>
<p>http协议包含由浏览器发送数据到服务器需要遵循的请求协议与服务器发送数据到浏览器需要遵循的请求协议。用于HTTP协议交互的信被为HTTP报文。请求端(客户端)的HTTP报文 做请求报文,响应端(服务器端)的 做响应报文。HTTP报文本身是由多行数据构成的字文本。</p>
</blockquote>
<img src="/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/image-20230406143917589.png" class>

<p>一个完整的URL包括：协议、ip、端口、路径、参数  </p>
<p>例如： <a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=yuan">https://www.baidu.com/s?wd=yuan</a>     其中https是协议，<a target="_blank" rel="noopener" href="http://www.baidu.com/">www.baidu.com</a> 是IP，端口默认80，/s是路径，参数是wd=yuan</p>
<p>请求方式: get与post请求</p>
<ul>
<li>GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditBook?name=test1&amp;id=123456. POST方法是把提交的数据放在HTTP包的请求体中.</li>
<li>GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制</li>
</ul>
<p>响应状态码：状态码的职 是当客户端向服务器端发送请求时, 返回的请求 结果。借助状态码,用户可以知道服务器端是正常 理了请求,还是出 现了 。状态码如200 OK,以3位数字和原因组成。</p>
<ol start="4">
<li>浏览器开发者工具</li>
</ol>
<p>在网页时通过F12即可进入开发者模式。</p>
<h2 id="前端基础"><a href="#前端基础" class="headerlink" title="前端基础"></a>前端基础</h2><h3 id="html基础-HTML基础-bkys的客栈-bkystop-github-io"><a href="#html基础-HTML基础-bkys的客栈-bkystop-github-io" class="headerlink" title="html基础(HTML基础 | bkys的客栈 (bkystop.github.io))"></a>html基础(<a href="https://bkystop.github.io/2022/05/07/HTML%E5%9F%BA%E7%A1%80/">HTML基础 | bkys的客栈 (bkystop.github.io)</a>)</h3><h3 id="css基础-CSS基础-bkys的客栈-bkystop-github-io"><a href="#css基础-CSS基础-bkys的客栈-bkystop-github-io" class="headerlink" title="css基础(CSS基础 | bkys的客栈 (bkystop.github.io))"></a>css基础(<a href="https://bkystop.github.io/2022/05/07/CSS%E5%9F%BA%E7%A1%80/">CSS基础 | bkys的客栈 (bkystop.github.io)</a>)</h3><h3 id="JavaScript基础-JavaScript基础-bkys的客栈-bkystop-github-io"><a href="#JavaScript基础-JavaScript基础-bkys的客栈-bkystop-github-io" class="headerlink" title="JavaScript基础(JavaScript基础 | bkys的客栈 (bkystop.github.io))"></a>JavaScript基础(<a href="https://bkystop.github.io/2022/05/30/JavaScript%E5%9F%BA%E7%A1%80/">JavaScript基础 | bkys的客栈 (bkystop.github.io)</a>)</h3><h2 id="数据解析"><a href="#数据解析" class="headerlink" title="数据解析"></a>数据解析</h2><h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>Regular Expression，译作正则表达式或正规表示法，表示有规则的表达式，正则表达式就是描述一段文本排列规则的表达式。</p>
<p>正则表达式是用于处理复杂文本信息的强大的高级文本操作工具。正则表达式拥有自己独特的规则语法以及一个独立的正则处理引擎，我们根据正则语法编写好规则（模式）以后，引擎不仅能够根据规则进行模糊文本查找，还可以进行模糊分割，替换等复杂的文本操作，能让开发者随心所欲地处理文本信息。正则引擎一般由编程语言提供操作，像python就提供了re模块或regex模块来调用正则处理引擎。</p>
<p>这是一套独立的编程语言，我们学习python的正则以后，也可以在java，php，go，javascript，sql等编程语言中使用。</p>
<p>正则对字符串或文本的操作，无非是分割、匹配、查找和替换。</p>
<p>在线测试工具  <a target="_blank" rel="noopener" href="http://tool.chinaz.com/regex/">http://tool.chinaz.com/regex/</a></p>
<ol>
<li>元字符(Metacharacters)</li>
</ol>
<p>元字符是具有特殊含义的字符。</p>
<table>
<thead>
<tr>
<th>元字符</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>.</strong></td>
<td align="left">叫通配符、万能通配符或通配元字符，匹配1个除了换行符\n以外任何原子</td>
</tr>
<tr>
<td><strong>[]</strong></td>
<td align="left">匹配一个中括号中出现的任意原子</td>
</tr>
<tr>
<td><strong>[^原子]</strong></td>
<td align="left">匹配一个没有在中括号出现的任意原子</td>
</tr>
<tr>
<td><strong>+</strong></td>
<td align="left">叫加号贪婪符，指定左边原子出现1次或多次</td>
</tr>
<tr>
<td>*****</td>
<td align="left">叫星号贪婪符，指定左边原子出现0次或多次</td>
</tr>
<tr>
<td><strong>?</strong></td>
<td align="left">叫非贪婪符，指定左边原子出现0次或1次</td>
</tr>
<tr>
<td><strong>{n,m}</strong></td>
<td align="left">叫数量范围贪婪符，指定左边原子的数量范围，有{n}，{n, }, {,m}, {n,m}四种写法，其中n与m必须是非负整数。</td>
</tr>
<tr>
<td><strong>^</strong></td>
<td align="left">叫开始边界符或开始锚点符，匹配一行的开头位置</td>
</tr>
<tr>
<td><strong>$</strong></td>
<td align="left">叫结束边界符或结束锚点符，匹配一行的结束位置</td>
</tr>
<tr>
<td><strong>|</strong></td>
<td align="left">指定原子或正则模式进行二选一或多选一</td>
</tr>
<tr>
<td><strong>()</strong></td>
<td align="left">对原子或正则模式进行捕获提取和分组划分整体操作，</td>
</tr>
<tr>
<td>*<em>\*</em></td>
<td align="left">转义字符，可以把原子转换特殊元字符，也可以把特殊元字符转成原子。</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="string">&quot;&quot;&quot;re.findall(正则模式, 文本)  基于正则模式查找所有匹配的文本内容&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># part1: 通配符-&gt;.  字符集-&gt; []</span></span><br><span class="line">ret1 = re.findall(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;a,b,c,d,e&quot;</span>)</span><br><span class="line">ret1 = re.findall(<span class="string">&quot;.&quot;</span>, <span class="string">&quot;a,b,c,d,e&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># part2:重复元字符-&gt; + * &#123;&#125; ?</span></span><br><span class="line">ret2 = re.findall(<span class="string">&quot;[0-9a-zA-Z]&quot;</span>, <span class="string">&quot;apple,banana,orange,melon&quot;</span>)</span><br><span class="line">ret2 = re.findall(<span class="string">&quot;\w&quot;</span>, <span class="string">&quot;apple,banana,orange,melon&quot;</span>)</span><br><span class="line">ret2 = re.findall(<span class="string">&quot;\w+&quot;</span>, <span class="string">&quot;apple,banana,orange,melon&quot;</span>)</span><br><span class="line">ret2 = re.findall(<span class="string">&quot;\w+?&quot;</span>, <span class="string">&quot;apple,banana,orange,melon&quot;</span>)  <span class="comment"># 取消贪婪匹配</span></span><br><span class="line">ret2 = re.findall(<span class="string">&quot;\w*&quot;</span>, <span class="string">&quot;apple,banana,orange,melon&quot;</span>)</span><br><span class="line">ret2 = re.findall(<span class="string">&quot;\w&#123;6&#125;&quot;</span>, <span class="string">&quot;apple,banana,orange,melon&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># part3: 位置元字符-&gt; ^ $</span></span><br><span class="line">ret3 = re.findall(<span class="string">&quot;^\w&#123;5&#125;&quot;</span>, <span class="string">&quot;apple,banana,peach,orange,melon&quot;</span>)</span><br><span class="line">ret3 = re.findall(<span class="string">&quot;\w&#123;5&#125;$&quot;</span>, <span class="string">&quot;apple,banana,peach,orange,melon&quot;</span>)</span><br><span class="line">ret3 = re.findall(<span class="string">&quot;^\w&#123;5&#125;$&quot;</span>, <span class="string">&quot;apple,banana,peach,orange,melon&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ret3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># part4:</span></span><br><span class="line"><span class="comment"># | 指定原子或正则模式进行二选一或多选一</span></span><br><span class="line"><span class="comment"># () 具备模式捕获的能力，也就是优先提取数据的能力，通过(?:) 可以取消模式捕获</span></span><br><span class="line">ret4 = re.findall(<span class="string">&quot;,\w&#123;5&#125;,&quot;</span>, <span class="string">&quot;,apple,banana,peach,orange,melon,&quot;</span>)  <span class="comment"># 筛选出5个字符的单词</span></span><br><span class="line">ret4 = re.findall(<span class="string">&quot;,(\w&#123;5&#125;),&quot;</span>, <span class="string">&quot;,apple,banana,peach,orange,melon,&quot;</span>)  <span class="comment"># 筛选出5个字符的单词</span></span><br><span class="line">ret4 = re.findall(<span class="string">&quot;\w+@\w+\.com&quot;</span>, <span class="string">&quot;123abc@163.com,....234xyz@qq.com,....&quot;</span>)  <span class="comment"># 筛选出5个字符的单词</span></span><br><span class="line">ret4 = re.findall(<span class="string">&quot;(\w+)@qq\.com&quot;</span>, <span class="string">&quot;123abc@163.com,....234xyz@qq.com,....&quot;</span>)  <span class="comment"># 筛选出5个字符的单词</span></span><br><span class="line">ret4 = re.findall(<span class="string">&quot;(?:\w+)@(?:qq|163)\.com&quot;</span>, <span class="string">&quot;123abc@163.com,....234xyz@qq.com,....&quot;</span>)  <span class="comment"># 筛选出5个字符的单词</span></span><br><span class="line"><span class="built_in">print</span>(ret4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># part5:  转义符-&gt; \d \D  \w \W      \n    \s \S  \b \B</span></span><br><span class="line"><span class="string">&quot;&quot;&quot; \b 1个单词边界原子 &quot;&quot;&quot;</span></span><br><span class="line">txt = <span class="string">&quot;my name is nana. nihao,nana&quot;</span></span><br><span class="line">ret = re.findall(<span class="string">r&quot;na&quot;</span>, txt)</span><br><span class="line">ret = re.findall(<span class="string">r&quot;\bna&quot;</span>, txt)</span><br><span class="line">ret = re.findall(<span class="string">r&quot;\bna\w&#123;2&#125;&quot;</span>, txt)</span><br><span class="line"><span class="built_in">print</span>(ret)  <span class="comment"># [&#x27;na&#x27;, &#x27;na&#x27;, &#x27;na&#x27;]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>转义元字符是<code>\</code>开头的元字符，由于某些正则模式会在开发中反复被用到，所以正则语法预定义了一些特殊正则模式以方便我们简写。</p>
<table>
<thead>
<tr>
<th>元字符</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td><strong>\d</strong></td>
<td>匹配一个数字原子，等价于<code>[0-9]</code>。</td>
<td>\d</td>
</tr>
<tr>
<td>\D</td>
<td>匹配一个非数字原子。等价于<code>[^0-9]</code>或<code>[^\d]</code>。</td>
<td>“\D”</td>
</tr>
<tr>
<td>\b</td>
<td>匹配一个单词边界原子，也就是指单词和空格间的位置。</td>
<td>er\b</td>
</tr>
<tr>
<td>\B</td>
<td>匹配一个非单词边界原子，等价于 <code>[^\b]</code></td>
<td>r”\Bain”r”ain\B”</td>
</tr>
<tr>
<td><strong>\n</strong></td>
<td>匹配一个换行符</td>
<td></td>
</tr>
<tr>
<td>\t</td>
<td>匹配一个制表符，tab键</td>
<td></td>
</tr>
<tr>
<td><strong>\s</strong></td>
<td>匹配一个任何空白字符原子，包括空格、制表符、换页符等等。等价于<code>[ \f\n\r\t\v]</code>。</td>
<td>“\s”</td>
</tr>
<tr>
<td>\S</td>
<td>匹配一个任何非空白字符原子。等价于<code>[^ \f\n\r\t\v]</code>或 <code>[^\s]</code>。</td>
<td>“\S”</td>
</tr>
<tr>
<td><strong>\w</strong></td>
<td>匹配一个包括下划线的单词原子。等价于<code>[A-Za-z0-9_]</code>。</td>
<td>“\w”</td>
</tr>
<tr>
<td>\W</td>
<td>匹配任何非单词字符。等价于<code>[^A-Za-z0-9_]</code> 或 <code>[^\w]</code>。</td>
<td>“\W”</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：python本身没有内置正则处理的，python中的正则就是一段字符串，我们需要使用python模块中提供的函数把字符串发送给正则引擎，正则引擎会把字符串转换成真正的正则表达式来处理文本内容。</p>
</blockquote>
<h4 id="re模块中的常用函数"><a href="#re模块中的常用函数" class="headerlink" title="re模块中的常用函数"></a>re模块中的常用函数</h4><p><code>re</code>模块提供了一组正则处理函数，使我们可以在字符串中搜索匹配项：</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><strong>findall</strong></td>
<td>按指定的正则模式查找文本中所有符合正则模式的匹配项，以列表格式返回结果。</td>
</tr>
<tr>
<td><strong>search</strong></td>
<td>在字符串中<strong>任何位置</strong>查找首个符合正则模式的匹配项，存在则返回re.Match对象，不存在返回None</td>
</tr>
<tr>
<td><strong>match</strong></td>
<td>判定字符串<strong>开始位置</strong>是否匹配正则模式的规则，匹配则返回re.Match对象，不匹配返回None</td>
</tr>
<tr>
<td><strong>split</strong></td>
<td>按指定的正则模式来分割字符串，返回一个分割后的列表</td>
</tr>
<tr>
<td><strong>sub</strong></td>
<td>把字符串按指定的正则模式来查找符合正则模式的匹配项，并可以替换一个或多个匹配项成其他内容。</td>
</tr>
</tbody></table>
<ul>
<li>如果一个正则表达式要使用几千遍，每一次都会编译，出于效率的考虑进行正则表达式的编译，就不需要每次都编译了，节省了编译的时间，从而提升效率</li>
<li>对于多次使用正则表达式，每一次编译都会浪费时间，为了提高效率，使用compile,不用每次都编译</li>
</ul>
<p><code>compile()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">re_email = re.<span class="built_in">compile</span>(<span class="string">r&quot;(?:\+86)?1[3-9]\d&#123;9&#125;&quot;</span>)</span><br><span class="line">ret = re_email.findall(<span class="string">&quot;15100649928,123@qq.com,13653287791,666@163.com&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(ret)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如果一个正则表达式要使用几千遍，每一次都会编译，出于效率的考虑进行正则表达式的编译，就不需要每次都编译了，节省了编译的时间，从而提升效率</p>
<h4 id="正则进阶"><a href="#正则进阶" class="headerlink" title="正则进阶"></a>正则进阶</h4><h4 id><a href="#" class="headerlink" title=".*?"></a><code>.*?</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">text = <span class="string">&#x27;&lt;12&gt; &lt;xyz&gt; &lt;!@#$%&gt; &lt;1a!#e2&gt; &lt;&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;\d+&gt;&quot;</span>, text)</span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;\w+&gt;&quot;</span>, text)</span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;.+&gt;&quot;</span>, text)</span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;.+?&gt;&quot;</span>, text)</span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;.*?&gt;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret)</span><br></pre></td></tr></table></figure>

<ul>
<li>模式修正符</li>
</ul>
<p>模式修正符，也叫正则修饰符，模式修正符就是给正则模式增强或增加功能的。</p>
<p><strong>通用flags（修正符）</strong></p>
<table>
<thead>
<tr>
<th align="left">值</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">re.I</td>
<td align="left">是匹配对大小写不敏感</td>
</tr>
<tr>
<td align="left">re.L</td>
<td align="left">做本地化识别匹配</td>
</tr>
<tr>
<td align="left">re.M</td>
<td align="left">多行匹配，影响到^和$</td>
</tr>
<tr>
<td align="left">re.S</td>
<td align="left">使.匹配包括换行符在内的所有字符</td>
</tr>
<tr>
<td align="left">re.U</td>
<td align="left">根据Unicode字符集解析字符，影响\w、\W、\b、\B</td>
</tr>
<tr>
<td align="left">re.X</td>
<td align="left">通过给予我们功能灵活的格式以便更好的理解正则表达式</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;12</span></span><br><span class="line"><span class="string">&gt;</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> &lt;x</span></span><br><span class="line"><span class="string"> yz&gt; </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> &lt;!@#$%&gt; </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> &lt;1a!#</span></span><br><span class="line"><span class="string"> e2&gt; </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> &lt;&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;.*?&gt;&quot;</span>, text)</span><br><span class="line">ret = re.findall(<span class="string">&quot;&lt;.*?&gt;&quot;</span>, text, re.S)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret)</span><br></pre></td></tr></table></figure>

<ul>
<li>常用的正则表达式</li>
</ul>
<table>
<thead>
<tr>
<th align="left">场景</th>
<th>正则表达式</th>
</tr>
</thead>
<tbody><tr>
<td align="left">用户名</td>
<td><code>^[a-z0-9_-]&#123;3,16&#125;$</code></td>
</tr>
<tr>
<td align="left">密码</td>
<td><code>^[a-z0-9_-]&#123;6,18&#125;$</code></td>
</tr>
<tr>
<td align="left">手机号码</td>
<td><code>^(?:\+86)?1[3-9]\d&#123;9&#125;$</code></td>
</tr>
<tr>
<td align="left">颜色的十六进制值</td>
<td>`^#?([a-f0-9]{6}</td>
</tr>
<tr>
<td align="left">电子邮箱</td>
<td><code>^[a-z\d]+(\.[a-z\d]+)*@([\da-z](-[\da-z])?)+\.[a-z]+$</code></td>
</tr>
<tr>
<td align="left">URL</td>
<td>`^(?:https://</td>
</tr>
<tr>
<td align="left">IP 地址</td>
<td>`((2[0-4]\d</td>
</tr>
<tr>
<td align="left"><strong>HTML 标签</strong></td>
<td><code>^&lt;([a-z]+)([^&lt;]+)*(?:&gt;(.*)&lt;\/\1&gt;</code></td>
</tr>
<tr>
<td align="left">utf-8编码下的汉字范围</td>
<td><code>^[\u2E80-\u9FFF]+$</code></td>
</tr>
</tbody></table>
<h3 id="BS4"><a href="#BS4" class="headerlink" title="BS4"></a>BS4</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>简单来说，Beautiful Soup是python的一个库，最主要的功能是从网页抓取数据。官方解释如下：</p>
<blockquote>
<p>Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。<br>它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。</p>
</blockquote>
<p>Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.你可能在寻找 Beautiful Soup3 的文档,Beautiful Soup 3 目前已经停止开发,官网推荐在现在的项目中使用Beautiful Soup 4。</p>
<blockquote>
<p>官方文档: <a target="_blank" rel="noopener" href="https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/">https://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/</a></p>
</blockquote>
<p>导入模块</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip install bs4 安装</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure>

<p>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install lxml</span><br></pre></td></tr></table></figure>

<p>另一个可供选择的解析器是纯Python实现的 html5lib , html5lib的解析方式与浏览器相同,可以选择下列方法来安装html5lib:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install html5lib</span><br></pre></td></tr></table></figure>

<p>解析器对比：</p>
<img src="/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/877318-20180816151649680-1825192992.png" class>

<p>简单使用：</p>
<ul>
<li>从一个<code>soup</code>对象开始，以下两种方式生成一个soup对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(<span class="built_in">open</span>(<span class="string">&quot;index.html&quot;</span>))    <span class="comment">##传入文件</span></span><br><span class="line">soup = BeautifulSoup(<span class="string">&quot;&lt;html&gt;data&lt;/html&gt;&quot;</span>)   <span class="comment">##文本</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>构造soup对象时，可以传入解析器参数，如果不传入的话，会以最好的方式去解析</p>
</blockquote>
<p>下面的一段HTML代码将作为例子被多次用到.这是 <em>爱丽丝梦游仙境的</em> 的一段内容(以后内容中简称为 <em>爱丽丝</em> 的文档):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>使用BeautifulSoup解析这段代码,能够得到一个 <code>BeautifulSoup</code> 的对象</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(html_doc, <span class="string">&#x27;html.parser&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>从文档中找到所有<a>标签的链接:</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;a&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(link.get(<span class="string">&#x27;href&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>从文档中获取所有文字内容:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(soup.get_text())</span><br></pre></td></tr></table></figure>

<h4 id="四种对象"><a href="#四种对象" class="headerlink" title="四种对象"></a>四种对象</h4><p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种<code>BeautifulSoup</code>， <code>Tag</code> , <code>NavigableString</code> ,   <code>Comment</code></p>
<p>tag对象，同网页中的<strong>标签</strong>的意思</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一、查找tag对象</span></span><br><span class="line">soup = BeautifulSoup(html_doc, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.head, <span class="built_in">type</span>(soup.head))</span><br><span class="line"><span class="built_in">print</span>(soup.title, <span class="built_in">type</span>(soup.title))</span><br><span class="line"><span class="built_in">print</span>(soup.a, <span class="built_in">type</span>(soup.a))  <span class="comment"># 第一个a标签，如果想获取所有a标签要用到soup.find_all(&#x27;a&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二、查找tag对象的标签名和属性</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.name)  <span class="comment"># a</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.b.name)  <span class="comment"># b</span></span><br><span class="line"><span class="built_in">print</span>(soup.a[<span class="string">&quot;href&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(soup.a.attrs)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">三、</span></span><br><span class="line"><span class="string">HTML 4定义了一系列可以包含多个值的属性.在HTML5中移除了一些,却增加更多.</span></span><br><span class="line"><span class="string">最常见的多值的属性是 class (一个tag可以有多个CSS的class). </span></span><br><span class="line"><span class="string">还有一些属性 rel , rev , accept-charset , headers , accesskey . </span></span><br><span class="line"><span class="string">在Beautiful Soup中多值属性的返回类型是list</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.a[<span class="string">&quot;class&quot;</span>])  <span class="comment"># 返回列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 四、tag的属性可以被添加,删除或修改(tag的属性操作方法与字典一样)</span></span><br><span class="line"><span class="comment"># soup.a[&quot;class&quot;] = [&quot;sister c1&quot;]</span></span><br><span class="line"><span class="comment"># del soup.a[&quot;id&quot;]</span></span><br><span class="line"><span class="comment"># print(soup)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 五、获取标签对象的文本内容</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.string)  <span class="comment"># p下的文本只有一个时，取到，否则为None</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.strings)  <span class="comment"># 拿到一个生成器对象, 取到p下所有的文本内容</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> soup.p.strings:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"><span class="comment"># 如果tag包含了多个子节点,tag就无法确定 .string 方法应该调用哪个子节点的内容, .string 的输出结果是 None，如果只有一个子节点那么就输出该子节点的文本，比如下面的这种结构，soup.p.string 返回为None,但soup.p.strings就可以找到所有文本</span></span><br><span class="line">p2 = soup.find_all(<span class="string">&quot;p&quot;</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(p2.string)</span><br><span class="line"><span class="built_in">print</span>(p2.strings)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> p2.strings:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line"><span class="comment"># text 和 string</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.string)</span><br><span class="line"><span class="built_in">print</span>(soup.p.text)  <span class="comment"># 取到p下所有的文本内容,text属性更常用，并且它可以直接过滤掉注释</span></span><br><span class="line"><span class="built_in">print</span>(p2.text)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这种情况下，会产生Comment对象</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">markup = &quot;<span class="tag">&lt;<span class="name">b</span>&gt;</span><span class="comment">&lt;!--Hey, buddy. Want to buy a used parser?--&gt;</span><span class="tag">&lt;/<span class="name">b</span>&gt;</span>&quot;</span><br><span class="line">soup = BeautifulSoup(markup,&quot;html.parser&quot;)</span><br><span class="line">comment = soup.b.string</span><br><span class="line">print(comment)</span><br><span class="line">print(type(comment))</span><br></pre></td></tr></table></figure>

<p><strong>结果为：</strong></p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hey, buddy. Want <span class="keyword">to</span> buy a used parser?</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="comment">&#x27;bs4.element.Comment&#x27;&gt;</span></span><br></pre></td></tr></table></figure>

<p>我们可以看到这时候.string返回的对象不再是<code>bs4.element.NavigableString</code>，而是<code>Comment</code></p>
<h4 id="遍历文档树（导航文档树）"><a href="#遍历文档树（导航文档树）" class="headerlink" title="遍历文档树（导航文档树）"></a>遍历文档树（导航文档树）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html_doc = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html_doc, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1、嵌套选择</span></span><br><span class="line"><span class="built_in">print</span>(soup.head.title.text)</span><br><span class="line"><span class="built_in">print</span>(soup.body.a.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、子节点、子孙节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.contents)  <span class="comment"># p下所有子节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.p.children)  <span class="comment"># 得到一个迭代器,包含p下所有子节点</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.p.children, <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(i, child)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.p.descendants)  <span class="comment"># 获取子孙节点,p下所有的标签都会选择出来</span></span><br><span class="line"><span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.p.descendants, <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(i, child)</span><br><span class="line"><span class="keyword">for</span> i, child <span class="keyword">in</span> <span class="built_in">enumerate</span>(soup.find_all(<span class="string">&quot;p&quot;</span>)[<span class="number">1</span>].descendants, <span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(i, child)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、父节点、祖先节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.parent)  <span class="comment"># 获取a标签的父节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.parent.text)  <span class="comment"># 获取a标签的父节点</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.parents)  <span class="comment"># 找到a标签所有的祖先节点，父亲的父亲，父亲的父亲的父亲...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、兄弟节点</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;===&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.a.next_sibling)  <span class="comment"># 下一个兄弟,类型：&lt;class &#x27;bs4.element.NavigableString&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(soup.a.next_sibling.next_sibling)</span><br><span class="line"><span class="built_in">print</span>(soup.a.previous_sibling.previous_sibling)</span><br><span class="line"><span class="built_in">print</span>(soup.a.previous_siblings)  <span class="comment"># 上面的兄弟们=&gt;生成器对象</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="搜索文档树"><a href="#搜索文档树" class="headerlink" title="搜索文档树"></a>搜索文档树</h4><ul>
<li>recursive 是否从当前位置递归往下查询，如果不递归，只会查询当前<code>soup</code>文档的子元素</li>
<li>string 这里是通过tag的内容来搜索，并且<strong>返回的是类容，而不是tag类型的元素</strong></li>
<li><code>**kwargs</code> 自动拆包接受属性值，所以才会有<code>soup.find_all(&#39;a&#39;,id=&#39;title&#39;)</code> ，id=’title’为<code>**kwargs</code>自动拆包掺入</li>
</ul>
<p>BeautifulSoup定义了很多搜索方法,这里着重介绍2个: find() 和 find_all() .其它方法的参数和用法类似</p>
<p>参数列表解读</p>
<ul>
<li> <code>find_all</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_all( name , attrs , recursive , string , **kwargs )</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>name参数</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html_doc, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一、 name 四种过滤器: 字符串、正则表达式、列表、方法</span></span><br><span class="line"><span class="comment"># 1、字符串：即标签名</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(name=<span class="string">&#x27;a&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、正则表达式</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(name=re.<span class="built_in">compile</span>(<span class="string">&#x27;^b&#x27;</span>)))  <span class="comment"># 找出b开头的标签，结果有body和b标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3、列表：如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有&lt;a&gt;标签和&lt;b&gt;标签:</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(name=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4、方法:如果没有合适过滤器,那么还可以定义一个方法,方法只接受一个元素参数 ,如果这个方法返回 True 表示当前元素匹配并且被找到,如果不是则反回 False</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">has_class_but_no_id</span>(<span class="params">tag</span>):</span><br><span class="line">    <span class="keyword">return</span> tag.has_attr(<span class="string">&#x27;class&#x27;</span>) <span class="keyword">and</span> tag.has_attr(<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(name=has_class_but_no_id))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>keyword 参数</strong></li>
</ul>
<p>如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 <code>id</code> 的参数,Beautiful Soup会搜索每个tag的”id”属性.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(soup.find_all(href=<span class="string">&quot;http://example.com/tillie&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.find_all(href=re.<span class="built_in">compile</span>(<span class="string">&quot;^http://&quot;</span>)))</span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="built_in">id</span>=<span class="literal">True</span>)) <span class="comment"># 拥有id属性的tag</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(href=re.<span class="built_in">compile</span>(<span class="string">&quot;http://&quot;</span>), <span class="built_in">id</span>=<span class="string">&#x27;link1&#x27;</span>) <span class="comment"># 多个属性</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&quot;a&quot;</span>, class_=<span class="string">&quot;sister&quot;</span>)) <span class="comment"># 注意，class是Python的关键字，所以class属性用class_</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&quot;a&quot;</span>,attrs=&#123;<span class="string">&quot;href&quot;</span>: re.<span class="built_in">compile</span>(<span class="string">&quot;^http://&quot;</span>), <span class="string">&quot;id&quot;</span>: re.<span class="built_in">compile</span>(<span class="string">&quot;^link[12]&quot;</span>)&#125;))      </span><br><span class="line"><span class="comment"># 通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag:</span></span><br><span class="line">data_soup.find_all(attrs=&#123;<span class="string">&quot;data-foo&quot;</span>: <span class="string">&quot;value&quot;</span>&#125;)    </span><br></pre></td></tr></table></figure>

<ul>
<li><strong>text参数</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(text=<span class="string">&quot;Elsie&quot;</span>))</span><br><span class="line"><span class="comment"># [&#x27;Elsie&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(text=[<span class="string">&quot;Tillie&quot;</span>, <span class="string">&quot;Elsie&quot;</span>, <span class="string">&quot;Lacie&quot;</span>]))</span><br><span class="line"><span class="comment"># [&#x27;Elsie&#x27;, &#x27;Lacie&#x27;, &#x27;Tillie&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只要包含Dormouse就可以</span></span><br><span class="line"><span class="built_in">print</span>(soup.find_all(text=re.<span class="built_in">compile</span>(<span class="string">&quot;Dormouse&quot;</span>)))</span><br><span class="line"><span class="comment"># [&quot;The Dormouse&#x27;s story&quot;, &quot;The Dormouse&#x27;s story&quot;]</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>limit参数</strong></li>
</ul>
<p><code>find_all()</code> 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 <code>limit</code> 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 <code>limit</code> 的限制时,就停止搜索返回结果.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&quot;a&quot;</span>,limit=<span class="number">2</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>recursive 参数</strong></li>
</ul>
<p>调用tag的 <code>find_all()</code> 方法时,Beautiful Soup会检索当前tag的所有子孙节点,如果只想搜索tag的直接子节点,可以使用参数 <code>recursive=False</code> </p>
<ul>
<li><code>find</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find( name , attrs , recursive , string , **kwargs )</span><br></pre></td></tr></table></figure>

<p><code>find_all()</code> 方法将返回文档中符合条件的所有tag,尽管有时候我们只想得到一个结果.比如文档中只有一个<body>标签,那么使用 <code>find_all()</code> 方法来查找<body>标签就不太合适, 使用 <code>find_all</code> 方法并设置 <code>limit=1</code> 参数不如直接使用 <code>find()</code> 方法.下面两行代码是等价的:</body></body></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(<span class="string">&#x27;title&#x27;</span>, limit=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># [&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]</span></span><br><span class="line"></span><br><span class="line">soup.find(<span class="string">&#x27;title&#x27;</span>)</span><br><span class="line"><span class="comment"># &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>唯一的区别是 <code>find_all()</code> 方法的返回结果是值包含一个元素的列表,而 <code>find()</code> 方法直接返回结果.<code>find_all()</code> 方法没有找到目标是返回空列表, <code>find()</code> 方法找不到目标时,返回 <code>None</code> .</strong></p>
<p><code>soup.head.title</code> 是 tag的名字 方法的简写.这个简写的原理就是多次调用当前tag的 <code>find()</code> 方法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">soup.head.title</span><br><span class="line"><span class="comment"># &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;</span></span><br><span class="line"></span><br><span class="line">soup.find(<span class="string">&quot;head&quot;</span>).find(<span class="string">&quot;title&quot;</span>)</span><br><span class="line"><span class="comment"># &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>其它方法</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#（1） find_parents() 和 find_parent()</span></span><br><span class="line">a_string = soup.find(text=<span class="string">&quot;Lacie&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(a_string)  <span class="comment"># Lacie</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a_string.find_parent())</span><br><span class="line"><span class="comment"># &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</span></span><br><span class="line"><span class="built_in">print</span>(a_string.find_parents())</span><br><span class="line"><span class="built_in">print</span>(a_string.find_parent(<span class="string">&quot;p&quot;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;p class=&quot;story&quot;&gt;</span></span><br><span class="line"><span class="string">    Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">    &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">    &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">    &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">    and they lived at the bottom of a well.</span></span><br><span class="line"><span class="string">&lt;/p&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># （2）find_next_siblings() 和 find_next_sibling()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这2个方法通过 .next_siblings 属性对当tag的所有后面解析的兄弟tag节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点, find_next_sibling() 只返回符合条件的后面的第一个tag节点.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">first_link = soup.a</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(first_link.find_next_sibling(<span class="string">&quot;a&quot;</span>))</span><br><span class="line"><span class="comment"># &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(first_link.find_next_siblings(<span class="string">&quot;a&quot;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</span></span><br><span class="line"><span class="string">]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># find_previous_siblings() 和 find_previous_sibling()的使用类似于find_next_sibling和find_next_siblings。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># （3）find_all_next() 和 find_next()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">这2个方法通过 .next_elements 属性对当前tag的之后的tag和字符串进行迭代, find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点:　</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">first_link = soup.a</span><br><span class="line"><span class="built_in">print</span>(first_link.find_all_next(string=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># [&#x27;Elsie&#x27;, &#x27;,\n&#x27;, &#x27;Lacie&#x27;, &#x27; and\n&#x27;, &#x27;Tillie&#x27;, &#x27;;\nand they lived at the bottom of a well.&#x27;, &#x27;\n&#x27;, &#x27;...&#x27;, &#x27;\n&#x27;]</span></span><br><span class="line"><span class="built_in">print</span>(first_link.find_next(string=<span class="literal">True</span>)) <span class="comment"># Elsie</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># find_all_previous() 和 find_previous()的使用类似于find_all_next() 和 find_next()。</span></span><br></pre></td></tr></table></figure>

<h4 id="Css选择器"><a href="#Css选择器" class="headerlink" title="Css选择器"></a>Css选择器</h4><ul>
<li>select</li>
</ul>
<p>css选择器的方法为select(css_selector)<br>目前支持的选择器如下案例，css选择器可以参考<a target="_blank" rel="noopener" href="https://www.w3school.com.cn/cssref/css_selectors.ASP">https://www.w3school.com.cn/cssref/css_selectors.ASP</a></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">soup.select(&quot;title&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">title</span>&gt;</span>The Dormouse&#x27;s story<span class="tag">&lt;/<span class="name">title</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;p nth-of-type(3)&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;story&quot;</span>&gt;</span>...<span class="tag">&lt;/<span class="name">p</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;body a&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span>  <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;html head title&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">title</span>&gt;</span>The Dormouse&#x27;s story<span class="tag">&lt;/<span class="name">title</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">soup.select(&quot;head &gt; title&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">title</span>&gt;</span>The Dormouse&#x27;s story<span class="tag">&lt;/<span class="name">title</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;p &gt; a&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span>  <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;p &gt; a:nth-of-type(2)&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;p &gt; #link1&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;body &gt; a&quot;)</span><br><span class="line"></span><br><span class="line">soup.select(&quot;#link1 ~ .sister&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span>  <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;#link1 + .sister&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">soup.select(&quot;.sister&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;[class~=sister]&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;#link1&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&quot;a#link2&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">soup.select(&quot;#link1,#link2&quot;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">soup.select(&#x27;a[href]&#x27;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&#x27;a[href=&quot;http://example.com/elsie&quot;]&#x27;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&#x27;a[href^=&quot;http://example.com/&quot;]&#x27;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&#x27;a[href$=&quot;tillie&quot;]&#x27;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line"></span><br><span class="line">soup.select(&#x27;a[href*=&quot;.com/el&quot;]&#x27;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>]</span><br><span class="line">multilingual_markup = &quot;&quot;&quot;</span><br><span class="line"> <span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span>Hello<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;en-us&quot;</span>&gt;</span>Howdy, y&#x27;all<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;en-gb&quot;</span>&gt;</span>Pip-pip, old fruit<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;fr&quot;</span>&gt;</span>Bonjour mes amis<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">multilingual_soup = BeautifulSoup(multilingual_markup)</span><br><span class="line">multilingual_soup.select(&#x27;p[lang|=en]&#x27;)</span><br><span class="line"># [<span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span>Hello<span class="tag">&lt;/<span class="name">p</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;en-us&quot;</span>&gt;</span>Howdy, y&#x27;all<span class="tag">&lt;/<span class="name">p</span>&gt;</span>,</span><br><span class="line">#  <span class="tag">&lt;<span class="name">p</span> <span class="attr">lang</span>=<span class="string">&quot;en-gb&quot;</span>&gt;</span>Pip-pip, old fruit<span class="tag">&lt;/<span class="name">p</span>&gt;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>select_one</li>
</ul>
<p><strong>返回查找到的元素的第一个</strong></p>
<ul>
<li>练习</li>
</ul>
<p>使用bs4爬取豆瓣电影排行榜信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(s, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line">s=soup.find_all(class_=<span class="string">&quot;item&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> s:</span><br><span class="line">  <span class="built_in">print</span>(item.find(class_=<span class="string">&quot;pic&quot;</span>).a.get(<span class="string">&quot;href&quot;</span>))</span><br><span class="line">  <span class="built_in">print</span>(item.find(class_=<span class="string">&quot;pic&quot;</span>).em.string)</span><br><span class="line">  <span class="built_in">print</span>(item.find(class_=<span class="string">&quot;info&quot;</span>).contents[<span class="number">1</span>].a.span.string)</span><br><span class="line">        <span class="built_in">print</span>(item.find(class_=<span class="string">&quot;info&quot;</span>).contents[<span class="number">3</span>].contents[<span class="number">3</span>].contents[<span class="number">3</span>].string)</span><br><span class="line">        <span class="built_in">print</span>(item.find(class_=<span class="string">&quot;info&quot;</span>).contents[<span class="number">3</span>].contents[<span class="number">3</span>].contents[<span class="number">7</span>].string)</span><br></pre></td></tr></table></figure>

<h3 id="3-3、xpath"><a href="#3-3、xpath" class="headerlink" title="3.3、xpath"></a><strong>3.3、xpath</strong></h3><p>xpath在Python的爬虫学习中，起着举足轻重的地位，对比正则表达式 re两者可以完成同样的工作，实现的功能也差不多，但xpath明显比re具有优势，在网页分析上使re退居二线。</p>
<p>xpath 全称为<strong>XML Path Language</strong> 一种小型的<strong>查询语言</strong><br>xpath的优点： </p>
<ul>
<li>可在XML中查找信息 </li>
<li>支持HTML的查找 </li>
<li>通过元素和属性进行导航</li>
</ul>
<p><strong>python开发使用XPath条件：</strong> 由于XPath属于lxml库模块，所以首先要安装库lxml。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">selector=etree.HTML(源码) <span class="comment">#将源码转化为能被XPath匹配的格式</span></span><br><span class="line">selector.xpath(表达式) <span class="comment">#返回为一列表</span></span><br></pre></td></tr></table></figure>

<h4 id="路径表达式"><a href="#路径表达式" class="headerlink" title="路径表达式"></a><strong>路径表达式</strong></h4><table>
<thead>
<tr>
<th align="left">表达式</th>
<th align="left">描述</th>
<th>实例</th>
<th>解析</th>
</tr>
</thead>
<tbody><tr>
<td align="left">/</td>
<td align="left">从根节点选取</td>
<td><code>/body/div[1]</code></td>
<td>选取根结点下的body下的第一个div标签</td>
</tr>
<tr>
<td align="left">//</td>
<td align="left">从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置</td>
<td><code>//a</code></td>
<td>选取文档中所有的a标签</td>
</tr>
<tr>
<td align="left">./</td>
<td align="left">当前节点再次进行xpath</td>
<td><code>./a</code></td>
<td>选取当前节点下的所有a标签</td>
</tr>
<tr>
<td align="left">@</td>
<td align="left">选取属性</td>
<td><code>//@calss</code></td>
<td>选取所有的class属性</td>
</tr>
</tbody></table>
<h4 id="谓语（Predicates）"><a href="#谓语（Predicates）" class="headerlink" title="** 谓语（Predicates）**"></a>** 谓语（Predicates）**</h4><p>谓语用来查找某个特定的节点或者包含某个指定的值的节点。</p>
<p>谓语被嵌在方括号中。</p>
<p>在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<table>
<thead>
<tr>
<th align="left">路径表达式</th>
<th align="left">结果</th>
</tr>
</thead>
<tbody><tr>
<td align="left">/ul/li[1]</td>
<td align="left">选取属于 ul子元素的第一个 li元素。</td>
</tr>
<tr>
<td align="left">/ul/li[last()]</td>
<td align="left">选取属于 ul子元素的最后一个 li元素。</td>
</tr>
<tr>
<td align="left">/ul/li[last()-1]</td>
<td align="left">选取属于 ul子元素的倒数第二个 li元素。</td>
</tr>
<tr>
<td align="left">//ul/li[position()&lt;3]</td>
<td align="left">选取最前面的两个属于 ul元素的子元素的 li元素。</td>
</tr>
<tr>
<td align="left">//a[@title]</td>
<td align="left">选取所有拥有名为 title的属性的 a元素。</td>
</tr>
<tr>
<td align="left">//a[@title=’xx’]</td>
<td align="left">选取所有 a元素，且这些元素拥有值为 xx的 title属性。</td>
</tr>
<tr>
<td align="left">//a[@title&gt;10] <code>&gt; &lt; &gt;= &lt;= !=</code></td>
<td align="left">选取 a元素的所有 title元素，且其中的 title元素的值须大于 10。</td>
</tr>
<tr>
<td align="left">/body/div[@price&gt;35.00]</td>
<td align="left">选取body下price元素值大于35的div节点</td>
</tr>
</tbody></table>
<h4 id="选取未知节点"><a href="#选取未知节点" class="headerlink" title="选取未知节点"></a><strong>选取未知节点</strong></h4><p>XPath 通配符可用来选取未知的 XML 元素。</p>
<table>
<thead>
<tr>
<th align="left">通配符</th>
<th align="left">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="left">*</td>
<td align="left">匹配任何元素节点。</td>
</tr>
<tr>
<td align="left">@*</td>
<td align="left">匹配任何属性节点。</td>
</tr>
<tr>
<td align="left">node()</td>
<td align="left">匹配任何类型的节点。</td>
</tr>
</tbody></table>
<p><strong>实例</strong></p>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<table>
<thead>
<tr>
<th align="left">路径表达式</th>
<th align="left">结果</th>
</tr>
</thead>
<tbody><tr>
<td align="left">/ul/*</td>
<td align="left">选取 bookstore 元素的所有子元素。</td>
</tr>
<tr>
<td align="left">//*</td>
<td align="left">选取文档中的所有元素。</td>
</tr>
<tr>
<td align="left">//title[@*]</td>
<td align="left">选取所有带有属性的 title 元素。</td>
</tr>
<tr>
<td align="left">//node()</td>
<td align="left">获取所有节点</td>
</tr>
</tbody></table>
<h4 id="选取若干路径"><a href="#选取若干路径" class="headerlink" title="选取若干路径"></a><strong>选取若干路径</strong></h4><p>通过在路径表达式中使用“|”运算符，您可以选取若干个路径。</p>
<p><strong>实例</strong></p>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<table>
<thead>
<tr>
<th align="left">路径表达式</th>
<th align="left">结果</th>
</tr>
</thead>
<tbody><tr>
<td align="left">//book/title | //book/price</td>
<td align="left">选取 book 元素的所有 title 和 price 元素。</td>
</tr>
<tr>
<td align="left">//title | //price</td>
<td align="left">选取文档中的所有 title 和 price 元素。</td>
</tr>
<tr>
<td align="left">/bookstore/book/title | //price</td>
<td align="left">选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。</td>
</tr>
</tbody></table>
<ul>
<li><p>逻辑运算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//div[@<span class="built_in">id</span>=<span class="string">&quot;head&quot;</span> <span class="keyword">and</span> @<span class="keyword">class</span>=<span class="string">&quot;s_down&quot;</span>] <span class="comment"># 查找所有id属性等于head并且class属性等于s_down的div标签</span></span><br><span class="line">//title | //price <span class="comment"># 选取文档中的所有 title 和 price 元素,“|”两边必须是完整的xpath路径</span></span><br></pre></td></tr></table></figure></li>
<li><p>属性查询</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//div[@<span class="built_in">id</span>] <span class="comment"># 找所有包含id属性的div节点</span></span><br><span class="line">//div[@<span class="built_in">id</span>=<span class="string">&quot;maincontent&quot;</span>]  <span class="comment"># 查找所有id属性等于maincontent的div标签</span></span><br><span class="line">//@<span class="keyword">class</span></span><br><span class="line">//li[@name=<span class="string">&quot;xx&quot;</span>]//text()  <span class="comment"># 获取li标签name为xx的里面的文本内容</span></span><br></pre></td></tr></table></figure></li>
<li><p>获取第几个标签 索引从1开始</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tree.xpath(<span class="string">&#x27;//li[1]/a/text()&#x27;</span>)  <span class="comment"># 获取第一个</span></span><br><span class="line">tree.xpath(<span class="string">&#x27;//li[last()]/a/text()&#x27;</span>)  <span class="comment"># 获取最后一个</span></span><br><span class="line">tree.xpath(<span class="string">&#x27;//li[last()-1]/a/text()&#x27;</span>)  <span class="comment"># 获取倒数第二个</span></span><br></pre></td></tr></table></figure></li>
<li><p>模糊查询</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//div[contains(@<span class="built_in">id</span>, <span class="string">&quot;he&quot;</span>)]  <span class="comment"># 查询所有id属性中包含he的div标签</span></span><br><span class="line">//div[starts-<span class="keyword">with</span>(@<span class="built_in">id</span>, <span class="string">&quot;he&quot;</span>)] <span class="comment"># 查询所有id属性中包以he开头的div标签</span></span><br><span class="line">//div/h1/text()  <span class="comment"># 查找所有div标签下的直接子节点h1的内容</span></span><br><span class="line">//div/a/@href   <span class="comment"># 获取a里面的href属性值 </span></span><br><span class="line">//*  <span class="comment">#获取所有</span></span><br><span class="line">//*[@<span class="keyword">class</span>=<span class="string">&quot;xx&quot;</span>]  <span class="comment">#获取所有class为xx的标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取节点内容转换成字符串</span></span><br><span class="line">c = tree.xpath(<span class="string">&#x27;//li/a&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">result=etree.tostring(c, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(result.decode(<span class="string">&#x27;UTF-8&#x27;</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h4><p>豆瓣Top250基于xpath解析：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://movie.douban.com/top250?start=0&quot;</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.82 Safari/537.36&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">resp = requests.get(url, headers=headers)</span><br><span class="line"></span><br><span class="line">tree = etree.HTML(resp.text)  <span class="comment"># 加载页面源代码</span></span><br><span class="line"></span><br><span class="line">items = tree.xpath(<span class="string">&#x27;//li/div[@class=&quot;item&quot;]/div[@class=&quot;info&quot;]&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">    title = item.xpath(<span class="string">&#x27;./div[@class=&quot;hd&quot;]/a/span[1]/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    rating_num = item.xpath(<span class="string">&#x27;./div[@class=&quot;bd&quot;]/div[@class=&quot;star&quot;]/span[@class=&quot;rating_num&quot;]/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    comment_num = item.xpath(<span class="string">&#x27;./div[@class=&quot;bd&quot;]/div[@class=&quot;star&quot;]/span[4]/text()&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(title, rating_num, comment_num)</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://bkystop.github.io">bkys</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://bkystop.github.io/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/">http://bkystop.github.io/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/Python%E7%88%AC%E8%99%AB/">Python爬虫</a></div><div class="post_share"><div class="social-share" data-image="https://th.bing.com/th/id/OIP.zyNsZRAsDyvjlDQ4-I9tPQHaDt?w=311&amp;h=175&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/02/17/MySQL%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/" title="MySQL常用指令"><img class="cover" src="https://tse4-mm.cn.bing.net/th/id/OIP-C.PreZo9daH5jaXIqu4iPxSgHaC9?w=317&amp;h=140&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">MySQL常用指令</div></div></a></div><div class="next-post pull-right"><a href="/2022/11/07/Windows%E6%90%AD%E5%BB%BADVWA%E9%9D%B6%E5%9C%BA/" title="Windows搭建DVWA靶场"><img class="cover" src="https://tse4-mm.cn.bing.net/th/id/OIP-C.qhftMzTkUUJQwfVoGep5NQHaEK?w=295&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Windows搭建DVWA靶场</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/04/09/Python%E7%88%AC%E5%8F%96%E6%96%97%E5%9B%BE%E7%BD%91/" title="Python爬取斗图网"><img class="cover" src="https://img.pkdoutu.com/production/uploads/image/2022/01/02/20220102105000_CLgSsy.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-09</div><div class="title">Python爬取斗图网</div></div></a></div><div><a href="/2022/07/05/Python%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3Top250/" title="Python爬取豆瓣Top250"><img class="cover" src="https://th.bing.com/th?id=OIP.pGkz0hbOs1pTvm4mXYLcMgHaDe&w=349&h=164&c=8&rs=1&qlt=90&o=6&dpr=1.3&pid=3.1&rm=2" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-07-05</div><div class="title">Python爬取豆瓣Top250</div></div></a></div><div><a href="/2023/03/22/%E5%B9%B6%E5%8F%91%E7%88%AC%E8%99%AB/" title="并发爬虫"><img class="cover" src="https://th.bing.com/th/id/OIP.mZKd3EMSqRKvhInKb8hl-wHaEK?w=333&h=187&c=7&r=0&o=5&dpr=1.3&pid=1.7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-22</div><div class="title">并发爬虫</div></div></a></div><div><a href="/2022/09/15/Django%E6%A1%86%E6%9E%B6/" title="Django框架"><img class="cover" src="https://th.bing.com/th?id=OSK.636c2b779ec3b5065539b011463d2b9f&w=188&h=132&c=7&o=6&dpr=1.3&pid=SANGAM" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-15</div><div class="title">Django框架</div></div></a></div><div><a href="/2022/08/28/Flask%E5%85%A5%E9%97%A8/" title="Flask入门"><img class="cover" src="https://www.w3cschool.cn/attachments/image/20181226/1545802618390094.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-28</div><div class="title">Flask入门</div></div></a></div><div><a href="/2022/09/07/Flsak%E6%A1%86%E6%9E%B6/" title="Flsak框架"><img class="cover" src="https://tse4-mm.cn.bing.net/th/id/OIP-C.y7VmsbXrQCUBy-Vt1mqmjAHaEK?w=271&h=183&c=7&r=0&o=5&dpr=1.3&pid=1.7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-07</div><div class="title">Flsak框架</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://th.bing.com/th/id/OIP.GKw_Efoi-Jsf_OzGf3BSDwHaEd?w=269&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">bkys</div><div class="author-info__description">135413545</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">30</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">9</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.</span> <span class="toc-text">爬虫是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">网络基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#http%E5%8D%8F%E8%AE%AE"><span class="toc-number">2.1.</span> <span class="toc-text">http协议</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80"><span class="toc-number">3.</span> <span class="toc-text">前端基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#html%E5%9F%BA%E7%A1%80-HTML%E5%9F%BA%E7%A1%80-bkys%E7%9A%84%E5%AE%A2%E6%A0%88-bkystop-github-io"><span class="toc-number">3.1.</span> <span class="toc-text">html基础(HTML基础 | bkys的客栈 (bkystop.github.io))</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#css%E5%9F%BA%E7%A1%80-CSS%E5%9F%BA%E7%A1%80-bkys%E7%9A%84%E5%AE%A2%E6%A0%88-bkystop-github-io"><span class="toc-number">3.2.</span> <span class="toc-text">css基础(CSS基础 | bkys的客栈 (bkystop.github.io))</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JavaScript%E5%9F%BA%E7%A1%80-JavaScript%E5%9F%BA%E7%A1%80-bkys%E7%9A%84%E5%AE%A2%E6%A0%88-bkystop-github-io"><span class="toc-number">3.3.</span> <span class="toc-text">JavaScript基础(JavaScript基础 | bkys的客栈 (bkystop.github.io))</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90"><span class="toc-number">4.</span> <span class="toc-text">数据解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="toc-number">4.1.</span> <span class="toc-text">正则表达式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#re%E6%A8%A1%E5%9D%97%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">4.1.1.</span> <span class="toc-text">re模块中的常用函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E8%BF%9B%E9%98%B6"><span class="toc-number">4.1.2.</span> <span class="toc-text">正则进阶</span></a></li><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">4.1.3.</span> <span class="toc-text">.*?</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BS4"><span class="toc-number">4.2.</span> <span class="toc-text">BS4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">4.2.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E7%A7%8D%E5%AF%B9%E8%B1%A1"><span class="toc-number">4.2.2.</span> <span class="toc-text">四种对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%8D%E5%8E%86%E6%96%87%E6%A1%A3%E6%A0%91%EF%BC%88%E5%AF%BC%E8%88%AA%E6%96%87%E6%A1%A3%E6%A0%91%EF%BC%89"><span class="toc-number">4.2.3.</span> <span class="toc-text">遍历文档树（导航文档树）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2%E6%96%87%E6%A1%A3%E6%A0%91"><span class="toc-number">4.2.4.</span> <span class="toc-text">搜索文档树</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Css%E9%80%89%E6%8B%A9%E5%99%A8"><span class="toc-number">4.2.5.</span> <span class="toc-text">Css选择器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3%E3%80%81xpath"><span class="toc-number">4.3.</span> <span class="toc-text">3.3、xpath</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%AF%E5%BE%84%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="toc-number">4.3.1.</span> <span class="toc-text">路径表达式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B0%93%E8%AF%AD%EF%BC%88Predicates%EF%BC%89"><span class="toc-number">4.3.2.</span> <span class="toc-text">** 谓语（Predicates）**</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%89%E5%8F%96%E6%9C%AA%E7%9F%A5%E8%8A%82%E7%82%B9"><span class="toc-number">4.3.3.</span> <span class="toc-text">选取未知节点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%89%E5%8F%96%E8%8B%A5%E5%B9%B2%E8%B7%AF%E5%BE%84"><span class="toc-number">4.3.4.</span> <span class="toc-text">选取若干路径</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B"><span class="toc-number">4.3.5.</span> <span class="toc-text">案例</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/04/09/Python%E7%88%AC%E5%8F%96%E6%96%97%E5%9B%BE%E7%BD%91/" title="Python爬取斗图网"><img src="https://img.pkdoutu.com/production/uploads/image/2022/01/02/20220102105000_CLgSsy.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python爬取斗图网"/></a><div class="content"><a class="title" href="/2023/04/09/Python%E7%88%AC%E5%8F%96%E6%96%97%E5%9B%BE%E7%BD%91/" title="Python爬取斗图网">Python爬取斗图网</a><time datetime="2023-04-09T09:14:16.000Z" title="Created 2023-04-09 17:14:16">2023-04-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/22/%E5%B9%B6%E5%8F%91%E7%88%AC%E8%99%AB/" title="并发爬虫"><img src="https://th.bing.com/th/id/OIP.mZKd3EMSqRKvhInKb8hl-wHaEK?w=333&amp;h=187&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="并发爬虫"/></a><div class="content"><a class="title" href="/2023/03/22/%E5%B9%B6%E5%8F%91%E7%88%AC%E8%99%AB/" title="并发爬虫">并发爬虫</a><time datetime="2023-03-22T07:48:04.000Z" title="Created 2023-03-22 15:48:04">2023-03-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/17/MySQL%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/" title="MySQL常用指令"><img src="https://tse4-mm.cn.bing.net/th/id/OIP-C.PreZo9daH5jaXIqu4iPxSgHaC9?w=317&amp;h=140&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL常用指令"/></a><div class="content"><a class="title" href="/2023/02/17/MySQL%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/" title="MySQL常用指令">MySQL常用指令</a><time datetime="2023-02-17T11:57:39.000Z" title="Created 2023-02-17 19:57:39">2023-02-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/" title="Python爬虫基础"><img src="https://th.bing.com/th/id/OIP.zyNsZRAsDyvjlDQ4-I9tPQHaDt?w=311&amp;h=175&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python爬虫基础"/></a><div class="content"><a class="title" href="/2023/02/06/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/" title="Python爬虫基础">Python爬虫基础</a><time datetime="2023-02-06T06:23:42.000Z" title="Created 2023-02-06 14:23:42">2023-02-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/07/Windows%E6%90%AD%E5%BB%BADVWA%E9%9D%B6%E5%9C%BA/" title="Windows搭建DVWA靶场"><img src="https://tse4-mm.cn.bing.net/th/id/OIP-C.qhftMzTkUUJQwfVoGep5NQHaEK?w=295&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.3&amp;pid=1.7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Windows搭建DVWA靶场"/></a><div class="content"><a class="title" href="/2022/11/07/Windows%E6%90%AD%E5%BB%BADVWA%E9%9D%B6%E5%9C%BA/" title="Windows搭建DVWA靶场">Windows搭建DVWA靶场</a><time datetime="2022-11-07T14:23:44.000Z" title="Created 2022-11-07 22:23:44">2022-11-07</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By bkys</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>